{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SongDemo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2XfId01lVTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "2c5c19f0-75f7-4f6f-bc51-f036cfa0f43f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from scipy.stats import kurtosis\n",
        "from scipy.stats import skew\n",
        "import csv\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "!pip install pafy\n",
        "!pip install youtube_dl\n",
        "!pip install pydub\n",
        "import pafy, librosa, youtube_dl, warnings\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pydub import AudioSegment"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pafy\n",
            "  Downloading https://files.pythonhosted.org/packages/74/69/829919eeadff695338f98fa12bb99e45490761a2010c8d688d88b6df194a/pafy-0.5.5-py2.py3-none-any.whl\n",
            "Installing collected packages: pafy\n",
            "Successfully installed pafy-0.5.5\n",
            "Collecting youtube_dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/46/31aa255d531b3d77880fc5492396ba421525b926a2f4db8be883495d1bdd/youtube_dl-2020.5.3-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2020.5.3\n",
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVUM3C4ElkmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "ec5b4b88-72d3-43aa-de7b-31d849011f67"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swLHw0Z8lnYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/EE461P_Project/Data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu3LmoyalozM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data from Dataframe\n",
        "X = df.drop(['genre'], axis=1)\n",
        "y = df['genre']\n",
        "\n",
        "# Scaling X Data\n",
        "scale = StandardScaler()\n",
        "x_scaled = pd.DataFrame(scale.fit_transform(X), columns = X.columns)\n",
        "\n",
        "# Encoding Y Data to integer from 0-9\n",
        "encoder = LabelEncoder()\n",
        "y_enc = encoder.fit_transform(y)\n",
        "\n",
        "#Performing LDA\n",
        "lda = LDA()\n",
        "x_lda = lda.fit_transform(x_scaled, y_enc)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_enc, test_size=0.25, random_state=42)\n",
        "x_train_lda, x_test_lda, y_train_lda, y_test_lda = train_test_split(x_lda, y_enc, test_size=0.25, random_state=42)\n",
        "\n",
        "# User for iterations below\n",
        "dataset = []\n",
        "dataset.append([x_train, x_test, y_train, y_test])\n",
        "dataset.append([x_train_lda, x_test_lda, y_train_lda, y_test_lda])\n",
        "xtrain, xtest, ytrain, ytest = range(0,4)\n",
        "\n",
        "# x_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc-LlUeplgfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "def get_features(y, sr):\n",
        "    # Features to concatenate in the final dictionary\n",
        "    features = {'centroid': None, 'roloff': None, 'flux': None, 'rmse': None,\n",
        "                'zcr': None, 'contrast': None, 'bandwidth': None, 'flatness': None, 'chroma_stft': None}\n",
        "    \n",
        "    # Count silence\n",
        "    if 0 < len(y):\n",
        "        y_sound, _ = librosa.effects.trim(y)\n",
        "    features['sample_silence'] = len(y) - len(y_sound)\n",
        "\n",
        "    # Using librosa to calculate the features\n",
        "    features['chroma_stft']=librosa.feature.chroma_stft(y=y, sr=sr).ravel()\n",
        "    features['centroid'] = librosa.feature.spectral_centroid(y, sr=sr).ravel()\n",
        "    features['roloff'] = librosa.feature.spectral_rolloff(y, sr=sr,).ravel()\n",
        "    features['zcr'] = librosa.feature.zero_crossing_rate(y).ravel()\n",
        "    features['rmse'] = librosa.feature.rms(y).ravel()\n",
        "    features['flux'] = librosa.onset.onset_strength(y=y, sr=sr).ravel()\n",
        "    features['contrast'] = librosa.feature.spectral_contrast(y, sr=sr).ravel()\n",
        "    features['bandwidth'] = librosa.feature.spectral_bandwidth(y, sr=sr).ravel()\n",
        "    features['flatness'] = librosa.feature.spectral_flatness(y).ravel()\n",
        "    \n",
        "    # MFCC treatment\n",
        "    mfcc = librosa.feature.mfcc(y, sr=sr, n_mfcc=13)\n",
        "    for idx, v_mfcc in enumerate(mfcc):\n",
        "        features['mfcc_{}'.format(idx)] = v_mfcc.ravel()\n",
        "        \n",
        "    # Get statistics from the vectors\n",
        "    def get_moments(descriptors):\n",
        "        result = {}\n",
        "        for k, v in descriptors.items():\n",
        "            result['{}_max'.format(k)] = np.max(v)\n",
        "            result['{}_min'.format(k)] = np.min(v)\n",
        "            result['{}_mean'.format(k)] = np.mean(v)\n",
        "            result['{}_std'.format(k)] = np.std(v)\n",
        "            result['{}_kurtosis'.format(k)] = kurtosis(v)\n",
        "            result['{}_skew'.format(k)] = skew(v)\n",
        "        return result\n",
        "    \n",
        "    dict_agg_features = get_moments(features)\n",
        "    dict_agg_features['tempo'] = librosa.beat.tempo(y, sr=sr)[0]\n",
        "    \n",
        "    return dict_agg_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfjiiGbXlbRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "ff82fd71-b619-4376-cf98-946324c07647"
      },
      "source": [
        "# All-Star - https://www.youtube.com/watch?v=5ZYgIrqELFw\n",
        "# Livin on a Prayer - https://www.youtube.com/watch?v=fDjhZva-6LE\n",
        "# Through the Fire and Flames - https://www.youtube.com/watch?v=Wbrrma9Cutk\n",
        "# Lose Yourself - https://www.youtube.com/watch?v=tR1ECf4sEpw\n",
        "# September - https://www.youtube.com/watch?v=wBNewLDy3pQ\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "  warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "\n",
        "  # Getting the video\n",
        "  video_url = \"https://www.youtube.com/watch?v=wBNewLDy3pQ\" # PASTE THE YOUTUBE URL HERE\n",
        "  video = pafy.new(url=video_url, basic=False, gdata=False)\n",
        "  length = video.length\n",
        "  stream = video.getbestaudio()\n",
        "  filename = stream.download()\n",
        "  print(\"Downloaded: '\" + video.title + '.' + stream.extension + \"'\")\n",
        "\n",
        "  # Convert to MP3\n",
        "  name = 'song.mp3'\n",
        "  wav_audio = AudioSegment.from_file((video.title + '.' + stream.extension), format=stream.extension)\n",
        "  audio = wav_audio.export(name, format=\"mp3\")\n",
        "  print(\"Converted into: '\" + name + \"'\")\n",
        "\n",
        "  # Extract Features\n",
        "  y, sr = librosa.load(name, duration = length-1)\n",
        "  features = get_features(y, sr)\n",
        "  features['genre'] = 'hiphop'\n",
        "  features = pd.DataFrame(features, index=[0])\n",
        "  print(\"Successfully Extracted Features\")\n",
        "\n",
        "  # Creating/Training Model\n",
        "  gnb = GaussianNB()\n",
        "  gnb.fit(dataset[1][xtrain], dataset[1][ytrain])\n",
        "\n",
        "  # Predicting Model\n",
        "  genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "  song_x = scale.transform(features.drop(['genre'], axis=1))\n",
        "  song_x = lda.transform(song_x)\n",
        "  song_y = features['genre']\n",
        "\n",
        "  prediction = gnb.predict(song_x)\n",
        "  predict_proba = gnb.predict_log_proba(song_x)\n",
        "\n",
        "  proba_genre = dict(zip(genres, predict_proba[0]))\n",
        "  proba_genre_sorted = sorted(proba_genre.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # Printing Results\n",
        "  print(\"================================\")\n",
        "  print(\"Predicted '\" + video.title + \"' as \" + str(encoder.inverse_transform(prediction)[0]).title())\n",
        "  print(\"Guess order is: \", end=\"\")\n",
        "  for x in proba_genre_sorted: print(x[0].title(), end=\", \")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "220\n",
            "\n",
            "Downloaded: 'Earth Wind And Fire, September [lyrics].webm'\n",
            "Converted into: 'song.mp3'\n",
            "Successfully Extracted Features\n",
            "=============================\n",
            "Predicted 'Earth Wind And Fire, September [lyrics]' as Hiphop\n",
            "Guess order is: Hiphop, Pop, Reggae, Disco, Jazz, Classical, Country, Metal, Blues, Rock, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08NEh6BWmUXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}